{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-21T14:50:52.438208Z","iopub.status.busy":"2024-03-21T14:50:52.437836Z","iopub.status.idle":"2024-03-21T14:50:52.455620Z","shell.execute_reply":"2024-03-21T14:50:52.454431Z","shell.execute_reply.started":"2024-03-21T14:50:52.438140Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import xgboost as xgb\n","from sklearn.metrics import log_loss\n","from scipy.interpolate import UnivariateSpline\n","import statsmodels.api as sm\n","import matplotlib.pyplot as plt\n","import collections\n","import scipy.stats as stats\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","import warnings\n","from tqdm import tqdm\n","from scipy.stats import linregress\n","\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","pd.set_option(\"display.max_column\", 999)\n","print(os.listdir(\"../input\"))\n","DATA_PATH = \"/kaggle/input/march-machine-learning-mania-2024/\"\n","seeds_2024 = pd.read_csv(DATA_PATH + \"2024_tourney_seeds.csv\")\n","fname_slots = DATA_PATH + 'MNCAATourneySlots.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-03-21T14:50:52.457946Z","iopub.status.busy":"2024-03-21T14:50:52.457439Z","iopub.status.idle":"2024-03-21T14:50:52.599012Z","shell.execute_reply":"2024-03-21T14:50:52.598142Z","shell.execute_reply.started":"2024-03-21T14:50:52.457694Z"},"trusted":true},"outputs":[],"source":["# Analyze a bracket submission\n","class BracketChecker(object):\n","    def __init__(self, fname_slots):\n","        self.fname_slots = fname_slots\n","        self.df_slots = self._make_df_slots(self.fname_slots)\n","        self.set_slots = set(self.df_slots['Slot'])\n","        self.n_slots = self.df_slots.shape[0]\n","        self.dict_next_slot = self._make_dict_next_slot()\n","        self.dict_paths_to_victory = self._make_dict_paths_to_victory()\n","        \n","    \n","    @staticmethod\n","    def _make_df_slots(fname_slots):\n","        '''Reduced version of dataframe containing the slots information\n","        Parameters\n","        ----------\n","        fname_slots : str\n","            path to the file containing tournament Slots info\n","            Mens or Womens tournament should result in the same output here\n","\n","        Returns\n","        -------\n","        df_slots : pandas DataFrame\n","            Slots info for NCAA tournament for Round 1 and later\n","\n","        '''\n","        df_slots = pd.read_csv(fname_slots)\n","        \n","        # Only keep slots that are part of the traditional \n","        # tournament (no play-ins)\n","        df_slots = df_slots[df_slots['Slot'].str.startswith('R')]     \n","        \n","        # except for play-ins (which we don't care about)\n","        # the tournament is the same structure every year\n","        # So, drop Season column and duplicate Slot entries\n","        df_slots.drop_duplicates('Slot', inplace=True)\n","        df_slots.drop(columns='Season', inplace=True)\n","        return df_slots\n","    \n","    def _make_dict_next_slot(self):\n","        '''Makes a dictionary where the value is the next Slot played by the \n","        team that wins the Slot specified by key.\n","        \n","        Returns\n","        -------\n","        next_slot : dict\n","        '''\n","        next_slot = {}\n","        for ir, r in self.df_slots.iterrows():\n","            next_slot[r['StrongSeed']] = r['Slot']\n","            next_slot[r['WeakSeed']] = r['Slot']\n","        return next_slot\n","    \n","    def _make_dict_paths_to_victory(self):\n","        '''Dictionary with paths to victory for every seed.\n","\n","        Returns\n","        -------\n","        paths : dict\n","            Each key is a Seed in the tournament.  Each value is an ordered\n","            list containing the Slots that must be won by that Seed to\n","            win the tournament\n","        '''\n","        seeds = [f'{region}{num:02d}' for region in list('WXYZ') \\\n","                 for num in range(1,17)]\n","        \n","        paths = {}\n","        for s in seeds:\n","            slot = s\n","            path = []\n","            while slot in self.dict_next_slot.keys():\n","                slot = self.dict_next_slot[slot]\n","                path.append(slot)\n","                \n","            paths[s] = path\n","        return paths\n","    \n","    def check_predicted_slots(self, df_bracket):\n","        '''Checks a bracket dataframe to see if all Slot predictions are\n","        present and there are no doubles or extra slots\n","        \n","        Note: this does not check for bracket consistency.\n","        \n","        Parameters\n","        ----------\n","        df_bracket : pandas DataFrame\n","            in the format of the submission file, but only a single bracket\n","            for a single tournament\n","\n","        Returns\n","        -------\n","        pass_check : bool\n","            the bracket contained 1 prediction for every required slot, \n","            and nothing extra\n","        errors: dict\n","            dictionary explaining the errors that were found. Supported are\n","            'missing' : list of slots that need to be predicted \n","                but were missing from the bracket\n","            'overrepped' : list of slots that were predicted more than \n","                once in the bracket(e.g., you picked two different teams\n","                                    to win the same slot)\n","            'extra' : of slots that were included in the bracket but should \n","                      not be (useful in case of typos)\n","        '''\n","        \n","        pass_check = (self.set_slots == set(df_bracket['Slot']) \\\n","                      and self.n_slots == df_bracket.shape[0])\n","        if pass_check:\n","            errors = {}\n","        else:\n","            # get the unique list of slots that are predicted and their counts\n","            pred_slots, count_pred_slots = np.unique(df_bracket['Slot'],\n","                                                 return_counts=True)\n","            \n","            set_pred_slots = set(pred_slots)\n","            overrepped_slots = list(pred_slots[count_pred_slots > 1])           \n","            missing_slots = list(self.set_slots.difference(set_pred_slots))\n","            extra_slots = list(set_pred_slots.difference(self.set_slots))\n","            \n","            errors = {'missing': missing_slots, 'overrepped': overrepped_slots,\n","                      'extra': extra_slots}\n","            \n","        return pass_check, errors\n","        \n","    def check_consistency(self, df_bracket):\n","        '''\n","        Checks to make sure that brackets adhere to the following consistency\n","        rule:\n","            \"The predictions in each bracket must follow valid tournament paths. \n","            In other words, if a team is predicted to win a game in Round N, \n","            that team must have also been predicted as the winner of Round \n","            N-1 in one of the respective feeder games. The winner of a game \n","            in Round 1 must be one of the two teams scheduled to play in that \n","            game.\n","            \n","        Parameters\n","        ----------\n","        df_bracket : pandas DataFrame\n","            in the format of the submission file, but only a single bracket\n","            for a single tournament\n","\n","        Returns\n","        -------\n","        pass_check : bool\n","            if True, the bracket passed the consistency check\n","        inconsistencies : dict\n","            dictionary where keys are Seeds that were deemed to have \n","            inconsistent paths in the tournament and values are the paths as\n","            they appeared in the bracket.\n","\n","        '''\n","        \n","        # predicted paths of teams according to this bracket\n","        predicted_paths = self.calc_predicted_paths(df_bracket)\n","        \n","        inconsistencies = {}\n","        # loop over predicted paths to see if they are possible in the \n","        # tournament\n","        for seed, path in predicted_paths.items():\n","            # allowed path to victory\n","            allowed_ptv = self.dict_paths_to_victory[seed]\n","            len_path = len(path)\n","            if path != allowed_ptv[0:len_path]:\n","                inconsistencies[seed] = path\n","        \n","        pass_check = (len(inconsistencies.keys()) == 0)\n","        \n","        return pass_check, inconsistencies\n","    \n","    @staticmethod\n","    def calc_predicted_paths(df_bracket):\n","        '''\n","        Calculates a dictionary of lists where keys are Seeds in the tournament\n","        and values are ordered lists of the predicted Slots won by that Seed\n","\n","        Parameters\n","        ----------\n","        df_bracket : pandas DataFrame\n","            in the format of the submission file, but only a single bracket\n","            for a single tournament\n","\n","        Returns\n","        -------\n","        dict of lists where keys are Seeds in the tournament\n","        and values are ordered lists of the predicted Slots won by that Seed\n","\n","        '''\n","        return df_bracket.groupby('Team')['Slot'].apply(sorted).to_dict()\n","\n","bracket_checker = BracketChecker(fname_slots)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-03-21T14:50:52.600798Z","iopub.status.busy":"2024-03-21T14:50:52.600301Z","iopub.status.idle":"2024-03-21T14:50:52.642701Z","shell.execute_reply":"2024-03-21T14:50:52.641913Z","shell.execute_reply.started":"2024-03-21T14:50:52.600741Z"},"trusted":true},"outputs":[],"source":["# Analyze a bracket score\n","def average_bracket_score(prediction_df: pd.DataFrame, tournament_result_df: pd.DataFrame):\n","    \"\"\"Compute the average bracket score given bracket predictions and results of one result.\"\"\"\n","    bracket_scores = []\n","    brackets = prediction_df.Bracket.unique()\n","    for bracket in brackets:\n","        bracket_prediction_df = prediction_df.query(\"Bracket == @bracket\")\n","        bracket_scores.append(bracket_score(bracket_prediction_df, tournament_result_df))\n","    return sum(bracket_scores) / len(bracket_scores)\n","\n","\n","def bracket_score(bracket_prediction_df: pd.DataFrame, tournament_result_df: pd.DataFrame):\n","    \"\"\"\n","    Compute the bracket score given a prediction and the result for a tournament \n","    (both in submission format). Each bracket will be awarded points based on the number \n","    of correct predictions per tournament round: 1, 2, 4, 8, 16, 32 points for each \n","    correct prediction in rounds 1, 2, 3, 4, 5, 6, respectively.\n","    \"\"\"\n","    score = (bracket_prediction_df\n","            .merge(\n","                tournament_result_df,\n","                on=[\"Tournament\", \"Slot\"],\n","                suffixes=(\"_pred\", \"_actual\")\n","             )\n","            .assign(\n","                points =  lambda x: 2 ** (x.Slot.str[1].astype(int) - 1),\n","                correct = lambda x: x.Team_pred == x.Team_actual,\n","                score = lambda x: x.points * x.correct\n","            )\n","            .score\n","            .sum()\n","            )\n","    return score\n","\n","def get_tournament_result(season: int, tournament: str):\n","    \"\"\"Return the result a specified tournament in the submission format.\"\"\"\n","    result_path = DATA_PATH +  f\"{tournament}NCAATourneyCompactResults.csv\"\n","    seed_path = DATA_PATH + f\"{tournament}NCAATourneySeeds.csv\"\n","    result_df = pd.read_csv(result_path)\n","    win_seed_df = pd.read_csv(seed_path).rename(columns={\"Seed\": \"WinningSeed\", \"TeamID\": \"WTeamID\"})\n","    lose_seed_df = pd.read_csv(seed_path).rename(columns={\"Seed\": \"LosingSeed\", \"TeamID\": \"LTeamID\"})\n","    result_df = (result_df\n","                    .merge(win_seed_df, on=[\"Season\", \"WTeamID\"])\n","                    .merge(lose_seed_df, on=[\"Season\", \"LTeamID\"])\n","                    .assign(\n","                        WinningSeed = lambda x: x.WinningSeed.str[:3],\n","                        LosingSeed = lambda x: x.LosingSeed.str[:3],\n","                    )\n","                    .loc[:, [\"Season\", \"WinningSeed\", \"LosingSeed\"]]\n","                    .query(\"Season == @season\")\n","                )\n","    return to_submission_format(result_df, tournament)\n","\n","\n","def to_submission_format(result_df: pd.DataFrame, tournament: str, bracket: int = 1):\n","    \"\"\"Transform result dataframe with cols 'WinningSeed' and 'LosingSeed' to submission format.\"\"\"\n","    bracket_df = pd.DataFrame(columns=[\"Slot\", \"Team\", \"Team1\", \"Team2\"])\n","    for rnd in range(1,7):\n","        slots = get_slots(rnd)\n","        round_df = pd.DataFrame({\"Slot\": slots, \"Team1\": \"\", \"Team2\": \"\", \"Team\": \"\"})\n","        fill_round_with_teams(rnd, round_df, bracket_df)\n","        fill_round_with_winners(round_df, result_df)\n","        bracket_df = pd.concat([bracket_df, round_df])\n","    bracket_df['RowId'] = list(range(1, 1+len(bracket_df)))\n","    bracket_df['Tournament'] = tournament\n","    bracket_df['Bracket'] = 1\n","    return bracket_df[['RowId', 'Tournament', 'Bracket', 'Slot', 'Team']]\n","\n","\n","def fill_round_with_teams(rnd: int, round_df: pd.DataFrame, bracket_df: pd.DataFrame):\n","    \"\"\"Fill 'Team1' and 'Team2' columns in the round_df DataFrame.\"\"\"\n","    for idx, row in round_df.iterrows():\n","        rnd = int(row.Slot[1])\n","        region = row.Slot[2]\n","        chalk_seed = row.Slot[3]\n","        if rnd == 1:\n","            round_df.at[idx, \"Team1\"] = region + chalk_seed.zfill(2)\n","            round_df.at[idx, \"Team2\"] = region + str(17 - int(chalk_seed)).zfill(2)\n","        else:\n","            team_1_prev_slot, team_2_prev_slot = get_prev_slots(rnd, region, chalk_seed)\n","            round_df.at[idx,\"Team1\"] = get_slot_winner(team_1_prev_slot, bracket_df)\n","            round_df.at[idx,\"Team2\"] = get_slot_winner(team_2_prev_slot, bracket_df)\n","\n","\n","def fill_round_with_winners(round_df: pd.DataFrame, result_df: pd.DataFrame):\n","    \"\"\"Fill 'Team' column in the round_df DataFrame.\"\"\"\n","    for idx, row in round_df.iterrows():\n","        team_1, team_2 = row[\"Team1\"], row[\"Team2\"]\n","        \n","        winning_team = (result_df\n","                        .query(\"(WinningSeed == @team_1 and LosingSeed == @team_2) or (WinningSeed == @team_2 and LosingSeed == @team_1)\")\n","                        .WinningSeed\n","                        .values[0]\n","                        )\n","        round_df.at[idx, \"Team\"] = winning_team\n","\n","\n","def get_slot_winner(slot: str, df: pd.DataFrame):\n","    \"\"\"Get the identifier of the winner of a given slot.\"\"\"\n","    return df.loc[df.Slot == slot, \"Team\"].values[0]\n","\n","\n","def get_prev_slots(rnd: int, region: str, chalk_seed: str):\n","    \"\"\"\n","    Given a slot in the tournament bracket, identified by the round, region, and chalk seed, this \n","    function returns the slots in the previous round where the teams in the specified slot were determined.\n","    \"\"\"\n","    if 2 <= rnd and rnd <= 4:\n","        return [f\"R{rnd-1}{region}{chalk_seed}\", f\"R{rnd-1}{region}{1+int(2**(4-(rnd-1))-int(chalk_seed))}\"]\n","    if rnd == 5:\n","        return [\"R4W1\", \"R4X1\"] if f\"{region}{chalk_seed}\" == \"WX\" else [\"R4Y1\", \"R4Z1\"]\n","    if rnd == 6:\n","        return [\"R5WX\", \"R5YZ\"]\n","\n","\n","def get_slots(rnd: int):\n","    \"\"\"Get list of all slots for a given round.\"\"\"\n","    if rnd >= 1 and rnd <= 4:\n","        return [f\"R{rnd}{region}{seed}\" for region in \"WXYZ\" for seed in range(1, 1+int(2 ** (4 - rnd)))]\n","    if rnd == 5:\n","        return [\"R5WX\", \"R5YZ\"]\n","    if rnd == 6:\n","        return [\"R6CH\"]\n","\n","def evaluate(prediction_df: pd.DataFrame, \n","             season: int,\n","             tournaments = ['M', 'W']):\n","    \"\"\"For a prediction for a previous tournament given in the submission format compute the target metric.\"\"\"\n","    tournament_scores = []\n","    for tournament in tournaments:\n","        tournament_prediction_df = prediction_df.query(\"Tournament == @tournament\")\n","        if len(tournament_prediction_df) != 63:\n","            continue\n","        tournament_result_df = get_tournament_result(season, tournament)\n","        tournament_scores.append(average_bracket_score(tournament_result_df, tournament_prediction_df))\n","    return sum(tournament_scores) / len(tournament_scores)"]},{"cell_type":"markdown","metadata":{"_uuid":"afe4811283fd6778ba3b67f2a469ab12b1b74c43"},"source":["# Load the data"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"512dcd34de61fd5e61cd08eccc1c9560362f4178","execution":{"iopub.execute_input":"2024-03-21T14:50:52.645818Z","iopub.status.busy":"2024-03-21T14:50:52.645029Z","iopub.status.idle":"2024-03-21T14:50:53.582911Z","shell.execute_reply":"2024-03-21T14:50:53.581929Z","shell.execute_reply.started":"2024-03-21T14:50:52.645735Z"},"trusted":true},"outputs":[],"source":["men_tourney_results = pd.read_csv(DATA_PATH + \"MNCAATourneyDetailedResults.csv\")\n","women_tourney_results = pd.read_csv(DATA_PATH + \"WNCAATourneyDetailedResults.csv\")\n","\n","men_seeds = pd.read_csv(DATA_PATH + \"MNCAATourneySeeds.csv\")\n","women_seeds = pd.read_csv(DATA_PATH + \"WNCAATourneySeeds.csv\")\n","\n","men_regular_results = pd.read_csv(DATA_PATH + \"MRegularSeasonDetailedResults.csv\")\n","women_regular_results = pd.read_csv(DATA_PATH + \"WRegularSeasonDetailedResults.csv\")\n","\n","men_teams = pd.read_csv(DATA_PATH + \"MTeams.csv\")[['TeamID', 'TeamName']]\n","women_teams = pd.read_csv(DATA_PATH + \"WTeams.csv\")[['TeamID', 'TeamName']]\n","\n","men_conferences = pd.read_csv(DATA_PATH + \"MTeamConferences.csv\")\n","women_conferences = pd.read_csv(DATA_PATH + \"WTeamConferences.csv\")\n","\n","# massey = pd.read_csv(DATA_PATH + \"MMasseyOrdinals.csv\")\n","\n","def prepare_data(df):\n","    dfswap = df[['Season', 'DayNum', 'LTeamID', 'LScore', 'WTeamID', 'WScore', 'WLoc', 'NumOT', \n","    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', \n","    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']]\n","\n","    dfswap.loc[df['WLoc'] == 'H', 'WLoc'] = 'A'\n","    dfswap.loc[df['WLoc'] == 'A', 'WLoc'] = 'H'\n","    df.columns.values[6] = 'location'\n","    dfswap.columns.values[6] = 'location'    \n","      \n","    df.columns = [x.replace('W','T1_').replace('L','T2_') for x in list(df.columns)]\n","    dfswap.columns = [x.replace('L','T1_').replace('W','T2_') for x in list(dfswap.columns)]\n","\n","    output = pd.concat([df, dfswap]).reset_index(drop=True)\n","    output.loc[output.location=='N','location'] = '0'\n","    output.loc[output.location=='H','location'] = '1'\n","    output.loc[output.location=='A','location'] = '-1'\n","    output.location = output.location.astype(int)\n","    \n","    output['PointDiff'] = output['T1_Score'] - output['T2_Score']\n","    \n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6a7bf779e16fe27aa89633ff78f89d452794aa84","execution":{"iopub.execute_input":"2024-03-21T14:50:53.584523Z","iopub.status.busy":"2024-03-21T14:50:53.584263Z","iopub.status.idle":"2024-03-21T14:50:54.882074Z","shell.execute_reply":"2024-03-21T14:50:54.880920Z","shell.execute_reply.started":"2024-03-21T14:50:53.584478Z"},"trusted":true},"outputs":[],"source":["men_regular_data = prepare_data(men_regular_results)\n","men_tourney_data = prepare_data(men_tourney_results)\n","women_regular_data = prepare_data(women_regular_results)\n","women_tourney_data = prepare_data(women_tourney_results)\n","\n","print(men_regular_data.shape)\n","print(men_tourney_data.shape)\n","print(women_regular_data.shape)\n","print(women_tourney_data.shape)\n","\n","men_regular_data.head()"]},{"cell_type":"markdown","metadata":{"_uuid":"6dbbc08907e17be459f936ed59e6f50a6dade35c"},"source":["# Feature engineering!"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"af44a1f421daf0af7b82d50c10024d9460171282","execution":{"iopub.execute_input":"2024-03-21T14:50:54.884471Z","iopub.status.busy":"2024-03-21T14:50:54.884068Z","iopub.status.idle":"2024-03-21T14:50:54.897066Z","shell.execute_reply":"2024-03-21T14:50:54.895925Z","shell.execute_reply.started":"2024-03-21T14:50:54.884396Z"},"trusted":true},"outputs":[],"source":["boxscore_cols = ['T1_Score', 'T2_Score', \n","        'T1_FGM', 'T1_FGA', 'T1_FGM3', 'T1_FGA3', 'T1_FTM', 'T1_FTA', 'T1_OR', 'T1_DR', 'T1_Ast', 'T1_TO', 'T1_Stl', 'T1_Blk', 'T1_PF', \n","        'T2_FGM', 'T2_FGA', 'T2_FGM3', 'T2_FGA3', 'T2_FTM', 'T2_FTA', 'T2_OR', 'T2_DR', 'T2_Ast', 'T2_TO', 'T2_Stl', 'T2_Blk', 'T2_PF', \n","        'PointDiff']\n","\n","# Only keep relevant columns\n","men_tourney_data = men_tourney_data[['Season', 'DayNum', 'T1_TeamID', 'T1_Score', 'T2_TeamID' ,'T2_Score', 'PointDiff']]\n","women_tourney_data = women_tourney_data[['Season', 'DayNum', 'T1_TeamID', 'T1_Score', 'T2_TeamID' ,'T2_Score', 'PointDiff']]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:50:54.900067Z","iopub.status.busy":"2024-03-21T14:50:54.899653Z","iopub.status.idle":"2024-03-21T14:50:55.648402Z","shell.execute_reply":"2024-03-21T14:50:55.647272Z","shell.execute_reply.started":"2024-03-21T14:50:54.899989Z"},"trusted":true},"outputs":[],"source":["men_regular_compact = pd.read_csv(DATA_PATH + \"MRegularSeasonCompactResults.csv\").query('Season >= 2003')\n","men_regular_compact['point_diff'] = men_regular_compact['WScore'] - men_regular_compact['LScore']\n","\n","num_win = men_regular_compact.groupby(['Season', 'WTeamID']).count()\n","num_win = num_win.reset_index()[['Season', 'WTeamID', 'DayNum']].rename(columns={\"DayNum\": \"num_wins\", \"WTeamID\": \"T1_TeamID\"})\n","\n","num_loss = men_regular_compact.groupby(['Season', 'LTeamID']).count()\n","num_loss = num_loss.reset_index()[['Season', 'LTeamID', 'DayNum']].rename(columns={\"DayNum\": \"num_losses\", \"LTeamID\": \"T1_TeamID\"})\n","\n","gap_win = men_regular_compact.groupby(['Season', 'WTeamID']).mean().reset_index()\n","gap_win = gap_win[['Season', 'WTeamID', 'point_diff']].rename(columns={\"point_diff\": \"T1_point_diff_wins\", \"WTeamID\": \"T1_TeamID\"})\n","\n","gap_loss = men_regular_compact.groupby(['Season', 'LTeamID']).mean().reset_index()\n","gap_loss = gap_loss[['Season', 'LTeamID', 'point_diff']].rename(columns={\"point_diff\": \"T1_point_diff_losses\", \"LTeamID\": \"T1_TeamID\"})\n","\n","men_more_regular_stats = pd.merge(num_win, num_loss, on=['Season', 'T1_TeamID'], how='left')\n","men_more_regular_stats = men_more_regular_stats.merge(gap_win, on=['Season', 'T1_TeamID'], how='left')\n","men_more_regular_stats = men_more_regular_stats.merge(gap_loss, on=['Season', 'T1_TeamID'], how='left')\n","men_more_regular_stats['T1_win_ratio'] = men_more_regular_stats['num_wins'] / (men_more_regular_stats['num_wins'] + men_more_regular_stats['num_losses'])\n","men_more_regular_stats.drop(['num_wins', 'num_losses'], axis=1, inplace=True)\n","\n","\n","\n","women_regular_compact = pd.read_csv(DATA_PATH + \"WRegularSeasonCompactResults.csv\").query('Season >= 2003')\n","women_regular_compact['point_diff'] = women_regular_compact['WScore'] - women_regular_compact['LScore']\n","\n","num_win = women_regular_compact.groupby(['Season', 'WTeamID']).count()\n","num_win = num_win.reset_index()[['Season', 'WTeamID', 'DayNum']].rename(columns={\"DayNum\": \"num_wins\", \"WTeamID\": \"T1_TeamID\"})\n","\n","num_loss = women_regular_compact.groupby(['Season', 'LTeamID']).count()\n","num_loss = num_loss.reset_index()[['Season', 'LTeamID', 'DayNum']].rename(columns={\"DayNum\": \"num_losses\", \"LTeamID\": \"T1_TeamID\"})\n","\n","gap_win = women_regular_compact.groupby(['Season', 'WTeamID']).mean().reset_index()\n","gap_win = gap_win[['Season', 'WTeamID', 'point_diff']].rename(columns={\"point_diff\": \"T1_point_diff_wins\", \"WTeamID\": \"T1_TeamID\"})\n","\n","gap_loss = women_regular_compact.groupby(['Season', 'LTeamID']).mean().reset_index()\n","gap_loss = gap_loss[['Season', 'LTeamID', 'point_diff']].rename(columns={\"point_diff\": \"T1_point_diff_losses\", \"LTeamID\": \"T1_TeamID\"})\n","\n","women_more_regular_stats = pd.merge(num_win, num_loss, on=['Season', 'T1_TeamID'], how='left')\n","women_more_regular_stats = women_more_regular_stats.merge(gap_win, on=['Season', 'T1_TeamID'], how='left')\n","women_more_regular_stats = women_more_regular_stats.merge(gap_loss, on=['Season', 'T1_TeamID'], how='left')\n","women_more_regular_stats['T1_win_ratio'] = women_more_regular_stats['num_wins'] / (women_more_regular_stats['num_wins'] + women_more_regular_stats['num_losses'])\n","women_more_regular_stats.drop(['num_wins', 'num_losses'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f9a9e13c103cda1cb629cb6a1e5812be3cbc58ba","execution":{"iopub.execute_input":"2024-03-21T14:50:55.650257Z","iopub.status.busy":"2024-03-21T14:50:55.649929Z","iopub.status.idle":"2024-03-21T14:50:56.359845Z","shell.execute_reply":"2024-03-21T14:50:56.358764Z","shell.execute_reply.started":"2024-03-21T14:50:55.650195Z"},"trusted":true},"outputs":[],"source":["# Mean regular season statistics\n","men_season_statistics = men_regular_data.groupby([\"Season\", 'T1_TeamID'])[boxscore_cols].agg([np.mean]).reset_index()\n","men_season_statistics.columns = [''.join(col).strip() for col in men_season_statistics.columns.values]\n","men_season_statistics.columns = [col.replace('mean', '_mean') for col in men_season_statistics.columns]\n","men_season_statistics = pd.merge(men_season_statistics, men_more_regular_stats, on=['Season', 'T1_TeamID'], how='left')\n","\n","women_season_statistics = women_regular_data.groupby([\"Season\", 'T1_TeamID'])[boxscore_cols].agg([np.mean]).reset_index()\n","women_season_statistics.columns = [''.join(col).strip() for col in women_season_statistics.columns.values]\n","women_season_statistics.columns = [col.replace('mean', '_mean') for col in women_season_statistics.columns]\n","women_season_statistics = pd.merge(women_season_statistics, women_more_regular_stats, on=['Season', 'T1_TeamID'], how='left')\n","\n","men_season_statistics_T1 = men_season_statistics.copy()\n","men_season_statistics_T2 = men_season_statistics.copy()\n","\n","women_season_statistics_T1 = women_season_statistics.copy()\n","women_season_statistics_T2 = women_season_statistics.copy()\n","\n","men_season_statistics_T1.columns = [\"T1_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(men_season_statistics_T1.columns)]\n","men_season_statistics_T2.columns = [\"T2_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(men_season_statistics_T2.columns)]\n","men_season_statistics_T1.columns.values[0] = \"Season\"\n","men_season_statistics_T2.columns.values[0] = \"Season\"\n","\n","women_season_statistics_T1.columns = [\"T1_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(women_season_statistics_T1.columns)]\n","women_season_statistics_T2.columns = [\"T2_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(women_season_statistics_T2.columns)]\n","women_season_statistics_T1.columns.values[0] = \"Season\"\n","women_season_statistics_T2.columns.values[0] = \"Season\"\n","\n","men_regular_stats = men_season_statistics_T1 \n","\n","women_regular_stats = women_season_statistics_T1"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"632f6a9c61b60ed1ea391aa784589356a228c429","execution":{"iopub.execute_input":"2024-03-21T14:50:56.361513Z","iopub.status.busy":"2024-03-21T14:50:56.361200Z","iopub.status.idle":"2024-03-21T14:50:56.452927Z","shell.execute_reply":"2024-03-21T14:50:56.451891Z","shell.execute_reply.started":"2024-03-21T14:50:56.361453Z"},"trusted":true},"outputs":[],"source":["# Team names\n","men_regular_stats = pd.merge(men_regular_stats, men_teams, left_on='T1_TeamID', right_on='TeamID', how='left')\n","men_regular_stats.rename(columns={'TeamName': 'T1_TeamName'}, inplace=True)\n","men_regular_stats.drop(columns=['TeamID'], inplace=True)\n","\n","women_regular_stats = pd.merge(women_regular_stats, women_teams, left_on='T1_TeamID', right_on='TeamID', how='left')\n","women_regular_stats.rename(columns={'TeamName': 'T1_TeamName'}, inplace=True)\n","women_regular_stats.drop(columns=['TeamID'], inplace=True)\n","\n","# Conferences\n","p6 = {'acc', 'sec', 'big_east', 'big_ten', 'big_twelve', 'pac_twelve'}\n","men_regular_stats = pd.merge(men_regular_stats, men_conferences, left_on=['T1_TeamID', 'Season'], right_on=['TeamID', 'Season'], how='left')\n","men_regular_stats.rename(columns={'ConfAbbrev': 'T1_Conference'}, inplace=True)\n","men_regular_stats.drop(columns=['TeamID'], inplace=True)\n","men_regular_stats['T1_power6'] = men_regular_stats['T1_Conference'].isin(p6).astype(int)\n","\n","women_regular_stats = pd.merge(women_regular_stats, women_conferences, left_on=['T1_TeamID', 'Season'], right_on=['TeamID', 'Season'], how='left')\n","women_regular_stats.rename(columns={'ConfAbbrev': 'T1_Conference'}, inplace=True)\n","women_regular_stats.drop(columns=['TeamID'], inplace=True)\n","women_regular_stats['T1_power6'] = women_regular_stats['T1_Conference'].isin(p6).astype(int)\n","\n","men_regular_stats.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"bbe5b07505a16c7fa38e486c11089dd68122ae56","execution":{"iopub.execute_input":"2024-03-21T14:50:56.454843Z","iopub.status.busy":"2024-03-21T14:50:56.454509Z","iopub.status.idle":"2024-03-21T14:50:56.609838Z","shell.execute_reply":"2024-03-21T14:50:56.608642Z","shell.execute_reply.started":"2024-03-21T14:50:56.454781Z"},"trusted":true},"outputs":[],"source":["# Last 14 & 28 days mean stats\n","men_last14days_stats_T1 = men_regular_data.loc[men_regular_data.DayNum>118].reset_index(drop=True)\n","men_last14days_stats_T1['win'] = np.where(men_last14days_stats_T1['PointDiff']>0,1,0)\n","men_last14days_stats_T1 = men_last14days_stats_T1.groupby(['Season','T1_TeamID'])['win'].mean().reset_index(name='T1_win_ratio_14d')\n","\n","women_last14days_stats_T1 = women_regular_data.loc[women_regular_data.DayNum>118].reset_index(drop=True)\n","women_last14days_stats_T1['win'] = np.where(women_last14days_stats_T1['PointDiff']>0,1,0)\n","women_last14days_stats_T1 = women_last14days_stats_T1.groupby(['Season','T1_TeamID'])['win'].mean().reset_index(name='T1_win_ratio_14d')\n","\n","men_last28days_stats_T1 = men_regular_data.loc[men_regular_data.DayNum>104].reset_index(drop=True)\n","men_last28days_stats_T1['win'] = np.where(men_last28days_stats_T1['PointDiff']>0,1,0)\n","men_last28days_stats_T1 = men_last28days_stats_T1.groupby(['Season','T1_TeamID'])['win'].mean().reset_index(name='T1_win_ratio_28d')\n","\n","women_last28days_stats_T1 = women_regular_data.loc[women_regular_data.DayNum>104].reset_index(drop=True)\n","women_last28days_stats_T1['win'] = np.where(women_last28days_stats_T1['PointDiff']>0,1,0)\n","women_last28days_stats_T1 = women_last28days_stats_T1.groupby(['Season','T1_TeamID'])['win'].mean().reset_index(name='T1_win_ratio_28d')\n","\n","men_regular_stats = pd.merge(men_regular_stats, men_last14days_stats_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n","men_regular_stats = pd.merge(men_regular_stats, men_last28days_stats_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n","\n","women_regular_stats = pd.merge(women_regular_stats, women_last14days_stats_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n","women_regular_stats = pd.merge(women_regular_stats, women_last28days_stats_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n","\n","men_regular_stats.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e2d6a4e33b062401088f472b698cc9cabff3a612","execution":{"iopub.execute_input":"2024-03-21T14:50:56.611994Z","iopub.status.busy":"2024-03-21T14:50:56.611563Z","iopub.status.idle":"2024-03-21T14:50:56.689893Z","shell.execute_reply":"2024-03-21T14:50:56.688919Z","shell.execute_reply.started":"2024-03-21T14:50:56.611916Z"},"trusted":true},"outputs":[],"source":["# Seeds\n","men_seeds['seed'] = men_seeds['Seed'].apply(lambda x: int(x[1:3]))\n","\n","women_seeds['seed'] = women_seeds['Seed'].apply(lambda x: int(x[1:3]))\n","\n","men_seeds_T1 = men_seeds[['Season','TeamID','seed']].copy()\n","men_seeds_T1.columns = ['Season','T1_TeamID','T1_seed']\n","\n","women_seeds_T1 = women_seeds[['Season','TeamID','seed']].copy()\n","women_seeds_T1.columns = ['Season','T1_TeamID','T1_seed']\n","\n","men_regular_stats = pd.merge(men_regular_stats, men_seeds_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n","\n","women_regular_stats = pd.merge(women_regular_stats, women_seeds_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n","\n","men_regular_stats.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:50:56.691839Z","iopub.status.busy":"2024-03-21T14:50:56.691527Z","iopub.status.idle":"2024-03-21T14:50:56.710518Z","shell.execute_reply":"2024-03-21T14:50:56.709675Z","shell.execute_reply.started":"2024-03-21T14:50:56.691789Z"},"trusted":true},"outputs":[],"source":["def calculate_elo(teams, data, initial_rating=2000, k=140):\n","    '''\n","    Function to calculate each teams elo-rating.\n","    \n","    Parameters:\n","    teams (array-like): Containing Team-IDs\n","    data (pd.DataFrame): DataFrame with all matches in chronological order\n","    - initial_rating (float): Initial rating of an unranked team (default: 2000).\n","    - k (float): K-factor, determining the impact of each match on team ratings (default: 140).\n","    \n","    Returns: \n","    - list: List containing the historical ratings of WTeam\n","    - list: List containing the historical ratings of LTeam\n","    '''\n","    \n","    # Dictionary to keep track of current ratings for each team\n","    team_dict = {}\n","    for team in teams:\n","        team_dict[team] = initial_rating\n","        \n","    # Lists to store ratings for each team in each game\n","    r1, r2 = [], []\n","\n","    # Iterate through the game data\n","    for ind, row in tqdm(data.iterrows(), total=len(data)):\n","        # Append current ratings for teams to lists\n","        r1.append(team_dict[row['WTeamID']])\n","        r2.append(team_dict[row['LTeamID']])\n","\n","        # Calculate expected outcomes based on Elo ratings\n","        rateW = 1 / (1 + 10 ** ((team_dict[row['LTeamID']] - team_dict[row['WTeamID']]) / initial_rating))\n","        rateL = 1 / (1 + 10 ** ((team_dict[row['WTeamID']] - team_dict[row['LTeamID']]) / initial_rating))\n","\n","        # Update ratings for winning and losing teams\n","        team_dict[row['WTeamID']] += k * (1 - rateW)\n","        team_dict[row['LTeamID']] += k * (0 - rateL)\n","\n","        # Ensure that ratings do not go below 1\n","        if team_dict[row['LTeamID']] < 1:\n","            team_dict[row['LTeamID']] = 1\n","        \n","    return r1, r2\n","\n","def create_elo_data(teams, data, initial_rating=2000, k=140):\n","    '''\n","    Function to create a DataFrame containing summary statistics of Elo ratings \n","    for teams based on historical match data.\n","    \n","    Parameters:\n","    - teams (array-like): Containing Team-IDs.\n","    - data (pd.DataFrame): DataFrame with all matches in chronological order.\n","    - initial_rating (float): Initial rating of an unranked team (default: 2000).\n","    - k (float): K-factor, determining the impact of each match on team ratings (default: 140).\n","    \n","    Returns: \n","    - DataFrame: DataFrame summarizing a team's Elo rating throughout a season.\n","    '''\n","    \n","    r1, r2 = calculate_elo(teams, data, initial_rating, k)\n","    \n","    # Concatenate arrays vertically\n","    seasons = np.concatenate([data.Season, data.Season])\n","    days = np.concatenate([data.DayNum, data.DayNum])\n","    teams = np.concatenate([data.WTeamID, data.LTeamID])\n","    tourney = np.concatenate([data.tourney, data.tourney])\n","    ratings = np.concatenate([r1, r2])\n","    # Create a DataFrame\n","    rating_df = pd.DataFrame({\n","        'Season': seasons,\n","        'DayNum': days,\n","        'TeamID': teams,\n","        'Rating': ratings,\n","        'Tourney': tourney\n","    })\n","\n","    # Sort DataFrame and remove tournament data\n","    rating_df.sort_values(['TeamID', 'Season', 'DayNum'], inplace=True)\n","    rating_df = rating_df[rating_df['Tourney'] == 0]\n","    grouped = rating_df.groupby(['TeamID', 'Season'])\n","    results = grouped['Rating'].agg(['mean', 'median', 'std', 'min', 'max', 'last'])\n","    results.columns = ['Rating_Mean', 'Rating_Median', 'Rating_Std', 'Rating_Min', 'Rating_Max', 'Rating_Last']\n","    results['Rating_Trend'] = grouped.apply(lambda x: linregress(range(len(x)), x['Rating']).slope)\n","\n","    results.reset_index(inplace=True)\n","    \n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:50:56.711924Z","iopub.status.busy":"2024-03-21T14:50:56.711585Z","iopub.status.idle":"2024-03-21T14:52:23.606279Z","shell.execute_reply":"2024-03-21T14:52:23.605234Z","shell.execute_reply.started":"2024-03-21T14:50:56.711871Z"},"trusted":true},"outputs":[],"source":["# Get ELO ratings for regular seasons\n","regular_m = pd.read_csv(DATA_PATH + 'MRegularSeasonCompactResults.csv')\n","tourney_m = pd.read_csv(DATA_PATH + 'MNCAATourneyCompactResults.csv')\n","teams_m = pd.read_csv(DATA_PATH + 'MTeams.csv')\n","\n","regular_m['tourney'] = 0\n","tourney_m['tourney'] = 1\n","\n","data_m = pd.concat([regular_m, tourney_m])\n","data_m.sort_values(['Season', 'DayNum'], inplace=True)\n","data_m.reset_index(inplace=True, drop=True)\n","\n","elo_df_men = create_elo_data(teams_m.TeamID, data_m)\n","\n","elo_df_men.rename(columns={'Rating_Mean': 'T1_rating_mean', 'Rating_Median': 'T1_rating_median', 'Rating_Std': 'T1_rating_std',\n","       'Rating_Min': 'T1_rating_min', 'Rating_Max': 'T1_rating_max', 'Rating_Last': 'T1_rating_last', 'Rating_Trend': 'T1_rating_trend'}, inplace=True)\n","men_regular_stats = pd.merge(men_regular_stats, elo_df_men, left_on=['Season', 'T1_TeamID'], right_on=['Season', 'TeamID'], how='left')\n","men_regular_stats.drop(columns=['TeamID'], inplace=True)\n","\n","\n","regular_w = pd.read_csv(DATA_PATH + 'WRegularSeasonCompactResults.csv')\n","tourney_w = pd.read_csv(DATA_PATH + 'WNCAATourneyCompactResults.csv')\n","teams_w = pd.read_csv(DATA_PATH + 'WTeams.csv')\n","\n","regular_w['tourney'] = 0\n","tourney_w['tourney'] = 1\n","\n","data_w = pd.concat([regular_w, tourney_w])\n","data_w.sort_values(['Season', 'DayNum'], inplace=True)\n","data_w.reset_index(inplace=True, drop=True)\n","\n","elo_df_women = create_elo_data(teams_w.TeamID, data_w)\n","\n","elo_df_women.rename(columns={'Rating_Mean': 'T1_rating_mean', 'Rating_Median': 'T1_rating_median', 'Rating_Std': 'T1_rating_std',\n","       'Rating_Min': 'T1_rating_min', 'Rating_Max': 'T1_rating_max', 'Rating_Last': 'T1_rating_last', 'Rating_Trend': 'T1_rating_trend'}, inplace=True)\n","women_regular_stats = pd.merge(women_regular_stats, elo_df_women, left_on=['Season', 'T1_TeamID'], right_on=['Season', 'TeamID'], how='left')\n","women_regular_stats.drop(columns=['TeamID'], inplace=True)\n","\n","men_regular_stats.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:23.608527Z","iopub.status.busy":"2024-03-21T14:52:23.608153Z","iopub.status.idle":"2024-03-21T14:52:24.015769Z","shell.execute_reply":"2024-03-21T14:52:24.014835Z","shell.execute_reply.started":"2024-03-21T14:52:23.608455Z"},"trusted":true},"outputs":[],"source":["# Advanced stats ONLY for tourney teams (ONLY MEN)\n","adv_stats = pd.read_csv('/kaggle/input/march-madness-data/KenPom Barttorvik.csv')\n","men_teams_adv_stats = adv_stats['TEAM'].unique()\n","orig_men_teams = men_teams['TeamName'].unique()\n","\n","team_dict = {\n","    'Abilene Christian': 'Abilene Chr',\n","    'Albany': 'SUNY Albany', \n","    'American': 'American Univ',\n","    'Arkansas Pine Bluff': 'Ark Pine Bluff',\n","    'Boston University': 'Boston Univ',\n","    'Cal St. Bakersfield': 'CS Bakersfield',\n","    'Cal St. Fullerton': 'CS Fullerton',\n","    'Cal St. Northridge': 'CS Northridge',\n","    'Coastal Carolina': 'Coastal Car',\n","    'College of Charleston': 'Col Charleston',\n","    'East Tennessee St.': 'ETSU',\n","    'Eastern Kentucky': 'E Kentucky',\n","    'Eastern Washington': 'E Washington',\n","    'Fairleigh Dickinson': 'F Dickinson',\n","    'Florida Atlantic': 'FL Atlantic',\n","    'Florida Gulf Coast': 'FL Gulf Coast',\n","    'George Washington': 'G Washington',\n","    'Grambling St.': 'Grambling',\n","    'Green Bay': 'WI Green Bay',\n","    'Kennesaw St.': 'Kennesaw',\n","    'Kent St.': 'Kent',\n","    'Little Rock': 'Ark Little Rock',\n","    'Louisiana Lafayette': 'Louisiana',\n","    'Loyola Chicago': 'Loyola-Chicago',\n","    'Middle Tennessee': 'MTSU',\n","    'Milwaukee': 'WI Milwaukee',\n","    'Mississippi Valley St.': 'MS Valley St',\n","    \"Mount St. Mary's\": \"Mt St Mary's\",\n","    'North Carolina A&T': 'NC A&T',\n","    'North Carolina Central': 'NC Central',\n","    'North Carolina St.': 'NC State',\n","    'North Dakota St.': 'N Dakota St',\n","    'Northern Colorado': 'N Colorado',\n","    'Northern Kentucky': 'N Kentucky',\n","    'Northwestern St.': 'Northwestern LA',\n","    'Prairie View A&M': 'Prairie View',\n","    \"Saint Joseph's\": \"St Joseph's PA\",\n","    'Saint Louis': 'St Louis',\n","    \"Saint Mary's\": \"St Mary's CA\",\n","    \"Saint Peter's\": \"St Peter's\",\n","    'South Dakota St.': 'S Dakota St',\n","    'Southeast Missouri St.': 'SE Missouri St',\n","    'Southern': 'Southern Univ',\n","    'St. Bonaventure': \"St Bonaventure\",\n","    \"St. John's\": \"St John's\",\n","    'Stephen F. Austin': 'SF Austin',\n","    'Texas A&M Corpus Chris': 'TAM C. Christi',\n","    'Texas Southern': 'TX Southern',\n","    'UTSA': 'UT San Antonio',\n","    'Western Kentucky': 'WKU',\n","    'Western Michigan': 'W Michigan'\n","}\n","\n","for index, row in adv_stats.iterrows():\n","    team_name = row['TEAM']\n","    if team_name in team_dict:\n","        adv_stats.at[index, 'TEAM'] = team_dict[team_name]\n","    elif team_name.endswith('.'):\n","        adv_stats.at[index, 'TEAM'] = team_name[:-1]\n","        \n","men_teams_adv_stats = adv_stats['TEAM'].unique()\n","missing_teams = [x for x in men_teams_adv_stats if x not in orig_men_teams]\n","print(\"Missing teams:\", missing_teams)\n","\n","adv_stats.drop(columns = ['CONF', 'CONF ID', 'QUAD NO', 'QUAD ID', 'TEAM NO', 'TEAM ID', 'SEED', 'ROUND', 'GAMES', 'W', 'L', 'WIN%'], inplace=True)\n","\n","adv_stats = pd.merge(adv_stats, men_teams, left_on='TEAM', right_on='TeamName', how='inner').drop(columns = ['TeamName', 'TEAM'])\n","T1_adv_stats = adv_stats.copy().rename(columns={\"YEAR\": \"Season\", \"TeamID\": \"T1_TeamID\"})\n","T2_adv_stats = adv_stats.copy().rename(columns={\"YEAR\": \"Season\", \"TeamID\": \"T2_TeamID\"})\n","\n","for col in T1_adv_stats.columns:\n","    if col.isupper():\n","        new_name = '_'.join(col.split())\n","        new_name = \"T1_\" + new_name\n","        T1_adv_stats.rename(columns={col: new_name}, inplace=True)\n","for col in T2_adv_stats.columns:\n","    if col.isupper():\n","        new_name = '_'.join(col.split())\n","        new_name = \"T2_\" + new_name\n","        T2_adv_stats.rename(columns={col: new_name}, inplace=True)\n","        \n","T2_adv_stats.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:24.017582Z","iopub.status.busy":"2024-03-21T14:52:24.017255Z","iopub.status.idle":"2024-03-21T14:52:24.408016Z","shell.execute_reply":"2024-03-21T14:52:24.406934Z","shell.execute_reply.started":"2024-03-21T14:52:24.017522Z"},"trusted":true},"outputs":[],"source":["# Tourney data\n","men_team2_regular_stats = men_regular_stats.copy()\n","women_team2_regular_stats = women_regular_stats.copy()\n","\n","for col in men_team2_regular_stats.columns:\n","    if col.startswith(\"T1_\"):\n","        new_col = col.replace(\"T1_\", \"T2_\")\n","        men_team2_regular_stats.rename(columns={col: new_col}, inplace=True)\n","\n","for col in women_team2_regular_stats.columns:\n","    if col.startswith(\"T1_\"):\n","        new_col = col.replace(\"T1_\", \"T2_\")\n","        women_team2_regular_stats.rename(columns={col: new_col}, inplace=True)\n","        \n","men_tourney_data = pd.merge(men_tourney_data, men_regular_stats, on = ['Season', 'T1_TeamID'], how = 'left')\n","men_tourney_data = pd.merge(men_tourney_data, T1_adv_stats, on=['Season', 'T1_TeamID'], how='inner')\n","men_tourney_data = pd.merge(men_tourney_data, men_team2_regular_stats, on = ['Season', 'T2_TeamID'], how = 'left')\n","men_tourney_data = pd.merge(men_tourney_data, T2_adv_stats, on=['Season', 'T2_TeamID'], how='inner')\n","men_tourney_data[\"Seed_diff\"] = men_tourney_data[\"T1_seed\"] - men_tourney_data[\"T2_seed\"]\n","\n","women_tourney_data = pd.merge(women_tourney_data, women_regular_stats, on = ['Season', 'T1_TeamID'], how = 'left')\n","women_tourney_data = pd.merge(women_tourney_data, women_team2_regular_stats, on = ['Season', 'T2_TeamID'], how = 'left')\n","women_tourney_data[\"Seed_diff\"] = women_tourney_data[\"T1_seed\"] - women_tourney_data[\"T2_seed\"]\n","\n","men_tourney_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:24.410196Z","iopub.status.busy":"2024-03-21T14:52:24.409893Z","iopub.status.idle":"2024-03-21T14:52:25.008974Z","shell.execute_reply":"2024-03-21T14:52:25.007593Z","shell.execute_reply.started":"2024-03-21T14:52:24.410135Z"},"trusted":true},"outputs":[],"source":["def fix_data(tourney_data):\n","    tourney_data = tourney_data.drop(columns = [ 'T1_FGM_mean',\n","     'T1_FGA_mean',\n","     'T1_FGM3_mean',\n","     'T1_FGA3_mean',\n","     'T1_FTM_mean',\n","     'T1_FTA_mean',\n","     'T1_OR_mean',\n","     'T1_DR_mean',\n","     'T1_Ast_mean',\n","     'T1_TO_mean',\n","     'T1_Stl_mean',\n","     'T1_Blk_mean',\n","     'T1_PF_mean',\n","     'T1_opponent_FGM_mean',\n","     'T1_opponent_FGA_mean',\n","     'T1_opponent_FGM3_mean',\n","     'T1_opponent_FGA3_mean',\n","     'T1_opponent_FTM_mean',\n","     'T1_opponent_FTA_mean',\n","     'T1_opponent_OR_mean',\n","     'T1_opponent_DR_mean',\n","     'T1_opponent_Ast_mean',\n","     'T1_opponent_TO_mean',\n","     'T1_opponent_Stl_mean',\n","     'T1_opponent_Blk_mean',\n","     'T1_opponent_PF_mean',\n","    'T2_FGM_mean',\n","     'T2_FGA_mean',\n","     'T2_FGM3_mean',\n","     'T2_FGA3_mean',\n","     'T2_FTM_mean',\n","     'T2_FTA_mean',\n","     'T2_OR_mean',\n","     'T2_DR_mean',\n","     'T2_Ast_mean',\n","     'T2_TO_mean',\n","     'T2_Stl_mean',\n","     'T2_Blk_mean',\n","     'T2_PF_mean',\n","     'T2_opponent_FGM_mean',\n","     'T2_opponent_FGA_mean',\n","     'T2_opponent_FGM3_mean',\n","     'T2_opponent_FGA3_mean',\n","     'T2_opponent_FTM_mean',\n","     'T2_opponent_FTA_mean',\n","     'T2_opponent_OR_mean',\n","     'T2_opponent_DR_mean',\n","     'T2_opponent_Ast_mean',\n","     'T2_opponent_TO_mean',\n","     'T2_opponent_Stl_mean',\n","     'T2_opponent_Blk_mean',\n","     'T2_opponent_PF_mean'])\n","\n","    columns_to_diff = [\n","     'Score_mean',\n","     'opponent_Score_mean',\n","     'PointDiff_mean',\n","     'point_diff_wins',\n","     'point_diff_losses',\n","     'win_ratio',\n","     'win_ratio_14d',\n","     'win_ratio_28d',\n","     'rating_mean',\n","     'rating_median',\n","     'rating_std',\n","     'rating_min',\n","     'rating_max',\n","     'rating_last',\n","     'rating_trend',\n","     'K_TEMPO',\n","     'K_TEMPO_RANK',\n","     'KADJ_T',\n","     'KADJ_T_RANK',\n","     'K_OFF',\n","     'KO_RANK',\n","     'KADJ_O',\n","     'KADJ_O_RANK',\n","     'K_DEF',\n","     'KD_RANK',\n","     'KADJ_D',\n","     'KADJ_D_RANK',\n","     'KADJ_EM',\n","     'KADJ_EM_RANK',\n","     'BADJ_EM',\n","     'BADJ_O',\n","     'BADJ_D',\n","     'BARTHAG',\n","     'EFG%',\n","     'EFG%D',\n","     'FTR',\n","     'FTRD',\n","     'TOV%',\n","     'TOV%D',\n","     'OREB%',\n","     'DREB%',\n","     'OP_OREB%',\n","     'OP_DREB%',\n","     'RAW_T',\n","     '2PT%',\n","     '2PT%D',\n","     '3PT%',\n","     '3PT%D',\n","     'BLK%',\n","     'BLKED%',\n","     'AST%',\n","     'OP_AST%',\n","     '2PTR',\n","     '3PTR',\n","     '2PTRD',\n","     '3PTRD',\n","     'BADJ_T',\n","     'AVG_HGT',\n","     'EFF_HGT',\n","     'EXP',\n","     'TALENT',\n","     'FT%',\n","     'OP_FT%',\n","     'PPPO',\n","     'PPPD',\n","     'ELITE_SOS',\n","     'WAB',\n","     'BADJ_EM_RANK',\n","     'BADJ_O_RANK',\n","     'BADJ_D_RANK',\n","     'BARTHAG_RANK',\n","     'EFG%_RANK',\n","     'EFGD%_RANK',\n","     'FTR_RANK',\n","     'FTRD_RANK',\n","     'TOV%_RANK',\n","     'TOV%D_RANK',\n","     'OREB%_RANK',\n","     'DREB%_RANK',\n","     'OP_OREB%_RANK',\n","     'OP_DREB%_RANK',\n","     'RAW_T_RANK',\n","     '2PT%_RANK',\n","     '2PT%D_RANK',\n","     '3PT%_RANK',\n","     '3PT%D_RANK',\n","     'BLK%_RANK',\n","     'BLKED%_RANK',\n","     'AST%_RANK',\n","     'OP_AST%_RANK',\n","     '2PTR_RANK',\n","     '3PTR_RANK',\n","     '2PTRD_RANK',\n","     '3PTRD_RANK',\n","     'BADJT_RANK',\n","     'AVG_HGT_RANK',\n","     'EFF_HGT_RANK',\n","     'EXP_RANK',\n","     'TALENT_RANK',\n","     'FT%_RANK',\n","     'OP_FT%_RANK',\n","     'PPPO_RANK',\n","     'PPPD_RANK',\n","     'ELITE_SOS_RANK'\n","    ]\n","\n","    # Loop through each column and compute the difference\n","    for col_suffix in columns_to_diff:\n","        t1_col = f'T1_{col_suffix}'\n","        t2_col = f'T2_{col_suffix}'\n","        diff_col = f'diff_{col_suffix}'\n","\n","        # Compute the difference and assign it to the new column\n","        tourney_data[diff_col] = tourney_data[t1_col] - tourney_data[t2_col]\n","\n","    off_def_pairs = [\n","        ('EFG%', 'EFG%D'),        # Effective Field Goal Percentage vs. Opponent Effective Field Goal Percentage\n","        ('FTR', 'FTRD'),          # Free Throw Rate vs. Opponent Free Throw Rate\n","        ('TOV%', 'TOV%D'),        # Turnover Percentage vs. Opponent Turnover Percentage\n","        ('OREB%', 'OP_OREB%'),    # Offensive Rebound Percentage vs. Opponent Offensive Rebound Percentage\n","        ('DREB%', 'OP_DREB%'),    # Defensive Rebound Percentage vs. Opponent Defensive Rebound Percentage\n","        ('2PT%', '2PT%D'),        # Two-Point Field Goal Percentage vs. Opponent Two-Point Field Goal Percentage\n","        ('3PT%', '3PT%D'),        # Three-Point Field Goal Percentage vs. Opponent Three-Point Field Goal Percentage\n","        ('AST%', 'OP_AST%'),       # Assist Percentage vs. Opponent Assist Percentage\n","        ('K_OFF', 'K_DEF'),       \n","        ('KADJ_O', 'KADJ_D'),       \n","        ('BADJ_O', 'BADJ_D'),   \n","        ('BLK%', 'BLKED%'),     \n","        ('PPPO', 'PPPD'),      # Pair 1: Points Per Possession Offense vs. Points Per Possession Defense\n","        ('FT%', 'OP_FT%')      # Pair 2: Free Throw Percentage vs. Opponent Free Throw Percentage\n","    ]\n","\n","    for off_col, def_col in off_def_pairs:\n","        t1_off_col = 'T1_' + off_col\n","        t2_off_col = 'T2_' + off_col\n","        t1_def_col = 'T1_' + def_col\n","        t2_def_col = 'T2_' + def_col\n","\n","        tourney_data['adj_T1_' + off_col] = tourney_data[t1_off_col] - tourney_data[t2_def_col]\n","        tourney_data['adj_T2_' + off_col] = tourney_data[t2_off_col] - tourney_data[t1_def_col]\n","    \n","    return tourney_data\n","\n","men_tourney_data = fix_data(men_tourney_data)\n","men_tourney_data.head(5)"]},{"cell_type":"markdown","metadata":{"_uuid":"c2ba59b62b09fc5b5514a2cca4ca5408e9a2b71a"},"source":["# Building models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:25.010866Z","iopub.status.busy":"2024-03-21T14:52:25.010496Z","iopub.status.idle":"2024-03-21T14:52:25.020496Z","shell.execute_reply":"2024-03-21T14:52:25.019397Z","shell.execute_reply.started":"2024-03-21T14:52:25.010802Z"},"trusted":true},"outputs":[],"source":["# XGBoost model config\n","def cauchyobj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    c = 5000 \n","    x =  preds-labels    \n","    grad = x / (x**2/c**2+1)\n","    hess = -c**2*(x**2-c**2)/(x**2+c**2)**2\n","    return grad, hess\n","\n","\n","param = {} \n","\n","# Testing:\n","# param['eval_metric'] =  'mae'\n","# param['booster'] = 'gbtree'\n","# param['eta'] = 0.05 #change to ~0.02 for final run (from 0.05)\n","# param['subsample'] = 0.35\n","# param['colsample_bytree'] = 0.7\n","# param['num_parallel_tree'] = 3 #recommend 10 (from 3)\n","# param['min_child_weight'] = 40 \n","# param['gamma'] = 10\n","# param['max_depth'] =  3\n","# param['silent'] = 1\n","# repeat_cv = 3 # recommend 10 (from 3)\n","\n","\n","# Submission:\n","param['eval_metric'] =  'mae'\n","param['booster'] = 'gbtree'\n","param['eta'] = 0.02 #change to ~0.02 for final run (from 0.05)\n","param['subsample'] = 0.35\n","param['colsample_bytree'] = 0.7\n","param['num_parallel_tree'] = 10 #recommend 10 (from 3)\n","param['min_child_weight'] = 40 \n","param['gamma'] = 10\n","param['max_depth'] =  3\n","param['silent'] = 1\n","repeat_cv = 10 # recommend 10 (from 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:25.022362Z","iopub.status.busy":"2024-03-21T14:52:25.021931Z","iopub.status.idle":"2024-03-21T14:52:25.035280Z","shell.execute_reply":"2024-03-21T14:52:25.034248Z","shell.execute_reply.started":"2024-03-21T14:52:25.022317Z"},"trusted":true},"outputs":[],"source":["def train_xgboost(dtrain):\n","    xgb_cv = []\n","\n","    for i in range(repeat_cv): \n","        print(f\"Fold repeater {i}\")\n","        xgb_cv.append(\n","            xgb.cv(\n","              params = param,\n","              dtrain = dtrain,\n","              obj = cauchyobj,\n","              num_boost_round = 3000,\n","              folds = KFold(n_splits = 5, shuffle = True, random_state = i),\n","              early_stopping_rounds = 25,\n","              verbose_eval = 50\n","            )\n","        )\n","\n","    iteration_counts = [np.argmin(x['test-mae-mean'].values) for x in xgb_cv]\n","    men_val_mae = [np.min(x['test-mae-mean'].values) for x in xgb_cv]\n","    print(iteration_counts, men_val_mae, \"\\n\\n\")\n","    return xgb_cv, iteration_counts"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:25.037071Z","iopub.status.busy":"2024-03-21T14:52:25.036752Z","iopub.status.idle":"2024-03-21T14:52:25.046891Z","shell.execute_reply":"2024-03-21T14:52:25.045500Z","shell.execute_reply.started":"2024-03-21T14:52:25.036991Z"},"trusted":true},"outputs":[],"source":["def oof_predictions(X, y, iteration_counts):\n","    oof_preds = []\n","    for i in range(repeat_cv):\n","        print(f\"Fold repeater {i}\")\n","        preds = y.copy()\n","        kfold = KFold(n_splits = 5, shuffle = True, random_state = i)    \n","        for train_index, val_index in kfold.split(X,y):\n","            dtrain_i = xgb.DMatrix(X[train_index], label = y[train_index])\n","            dval_i = xgb.DMatrix(X[val_index], label = y[val_index])  \n","            model = xgb.train(\n","                  params = param,\n","                  dtrain = dtrain_i,\n","                  num_boost_round = iteration_counts[i],\n","                  verbose_eval = 50\n","            )\n","            preds[val_index] = model.predict(dval_i)\n","        oof_preds.append(np.clip(preds,-30,30))\n","    print(\"MAE: \", mean_absolute_error(sum(oof_preds)/len(oof_preds), y), \"\\n\\n\")\n","    return oof_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:25.049324Z","iopub.status.busy":"2024-03-21T14:52:25.048755Z","iopub.status.idle":"2024-03-21T14:52:25.062650Z","shell.execute_reply":"2024-03-21T14:52:25.061753Z","shell.execute_reply.started":"2024-03-21T14:52:25.049064Z"},"trusted":true},"outputs":[],"source":["def raw_spline(X, y, oof_preds):\n","    spline_models = []\n","    for i in range(repeat_cv):\n","        dat = np.column_stack((oof_preds[i], np.where(y > 0, 1, 0)))\n","        dat = dat[np.argsort(dat[:, 0])]\n","        unique_preds, idx = np.unique(dat[:, 0], return_index=True)\n","        x_vals = unique_preds\n","        y_vals = np.array([np.mean(dat[dat[:, 0] == pred][:, 1]) for pred in x_vals])\n","        spline_model = UnivariateSpline(x_vals, y_vals)\n","        spline_models.append(spline_model)\n","        spline_fit = spline_model(oof_preds[i])\n","        print(f\"logloss of cvsplit {i}: {log_loss(np.where(y > 0, 1, 0), spline_fit)}\") \n","\n","    # Plotting\n","    pred_int = np.array(oof_preds[0], dtype=int)\n","    plot_df = pd.DataFrame({\"pred\": pred_int, \"label\": np.where(y > 0, 1, 0), \"spline\": spline_models[0](oof_preds[0])})\n","    plot_df = plot_df.groupby('pred')['spline', 'label'].mean().reset_index()\n","    plt.figure()\n","    plt.plot(plot_df['pred'], plot_df['spline'])\n","    plt.plot(plot_df['pred'], plot_df['label'])\n","    plt.show()\n","\n","    return spline_models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:25.064445Z","iopub.status.busy":"2024-03-21T14:52:25.063885Z","iopub.status.idle":"2024-03-21T14:52:25.079987Z","shell.execute_reply":"2024-03-21T14:52:25.078671Z","shell.execute_reply.started":"2024-03-21T14:52:25.064383Z"},"trusted":true},"outputs":[],"source":["def good_spline(raw_data, X, y, oof_preds):\n","    val_cv = []\n","    spline_model = []\n","    for i in range(repeat_cv):\n","        dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n","        dat = sorted(dat, key = lambda x: x[0])\n","        datdict = {}\n","        for pred, label in dat:\n","            if pred not in datdict:\n","                datdict[pred] = []\n","            datdict[pred].append(label)\n","        x_vals = np.array(list(datdict.keys()))\n","        y_vals = np.array([np.mean(labels) for labels in datdict.values()])\n","        spline_model.append(UnivariateSpline(x_vals, y_vals))\n","        spline_fit = spline_model[i](oof_preds[i])\n","        spline_fit = np.clip(spline_fit,0.02,0.98)\n","#         spline_fit[(raw_data.T1_seed==1) & (raw_data.T2_seed==16) & (raw_data.T1_Score > raw_data.T2_Score)] = 1.0\n","#         spline_fit[(raw_data.T1_seed==2) & (raw_data.T2_seed==15) & (raw_data.T1_Score > raw_data.T2_Score)] = 1.0\n","#         spline_fit[(raw_data.T1_seed==3) & (raw_data.T2_seed==14) & (raw_data.T1_Score > raw_data.T2_Score)] = 1.0\n","#         spline_fit[(raw_data.T1_seed==4) & (raw_data.T2_seed==13) & (raw_data.T1_Score > raw_data.T2_Score)] = 1.0\n","#         spline_fit[(raw_data.T1_seed==16) & (raw_data.T2_seed==1) & (raw_data.T1_Score < raw_data.T2_Score)] = 0.0\n","#         spline_fit[(raw_data.T1_seed==15) & (raw_data.T2_seed==2) & (raw_data.T1_Score < raw_data.T2_Score)] = 0.0\n","#         spline_fit[(raw_data.T1_seed==14) & (raw_data.T2_seed==3) & (raw_data.T1_Score < raw_data.T2_Score)] = 0.0\n","#         spline_fit[(raw_data.T1_seed==13) & (raw_data.T2_seed==4) & (raw_data.T1_Score < raw_data.T2_Score)] = 0.0\n","        val_cv.append(pd.DataFrame({\"y\":np.where(y>0,1,0), \"pred\":spline_fit, \"season\":raw_data.Season}))\n","        print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") \n","    val_cv = pd.concat(val_cv)\n","    val_cv = val_cv.groupby('season').apply(lambda x: log_loss(x.y, x.pred))\n","    print(val_cv)\n","    plot_df = pd.DataFrame({\"pred\":oof_preds[0], \"label\":np.where(y>0,1,0), \"spline\":spline_model[0](oof_preds[0])})\n","    plot_df[\"pred_int\"] = (plot_df[\"pred\"]).astype(int)\n","    plot_df = plot_df.groupby('pred_int')['spline','label'].mean().reset_index()\n","    plt.figure()\n","    plt.plot(plot_df.pred_int,plot_df.spline)\n","    plt.plot(plot_df.pred_int,plot_df.label)\n","    return spline_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:25.081608Z","iopub.status.busy":"2024-03-21T14:52:25.081293Z","iopub.status.idle":"2024-03-21T14:52:25.194896Z","shell.execute_reply":"2024-03-21T14:52:25.193989Z","shell.execute_reply.started":"2024-03-21T14:52:25.081548Z"},"trusted":true},"outputs":[],"source":["good_cols = ['Season', 'T1_TeamID', 'T2_TeamID', 'T1_TeamName', 'T2_TeamName', 'T1_seed', 'T2_seed', 'T1_Score', 'T2_Score', 'PointDiff', 'T1_rating_last', 'T2_rating_last']\n","excluded = ['Season', 'DayNum', 'T1_TeamID', 'T1_Score', 'T2_TeamID', 'T2_Score','PointDiff', 'T1_TeamName', 'T2_TeamName']\n","categorical_features = ['T1_Conference','T2_Conference', 'T1_power6', 'T2_power6']\n","men_ordinal_features = [c for c in men_tourney_data.columns if 'RANK' in c]\n","men_continuous_features = [c for c in men_tourney_data.columns if c not in categorical_features and c not in excluded and c not in men_ordinal_features]\n","women_continuous_features = [c for c in women_tourney_data.columns if c not in categorical_features and c not in excluded]\n","\n","men_train_data = men_tourney_data.query(\"Season < 2024\")\n","women_train_data = women_tourney_data.query(\"Season < 2024\")\n","\n","men_X_train = men_train_data.drop(columns=excluded)\n","men_y_train = men_train_data['PointDiff'].values\n","\n","women_X_train = women_train_data.drop(columns=excluded)\n","women_y_train = women_train_data['PointDiff'].values\n","\n","men_preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('cat', OneHotEncoder(sparse=False, handle_unknown='ignore'), categorical_features),  # One-hot encode categorical features\n","        ('num', StandardScaler(), men_continuous_features),  # Standardize numerical features\n","    ],\n","    remainder='passthrough'  # Pass through any features not explicitly transformed\n",")\n","\n","women_preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('cat', OneHotEncoder(sparse=False, handle_unknown='ignore'), categorical_features),  # One-hot encode categorical features\n","        ('num', StandardScaler(), women_continuous_features),  # Standardize numerical features\n","    ],\n","    remainder='passthrough'  # Pass through any features not explicitly transformed\n",")\n","\n","men_X_train_scaled = men_preprocessor.fit_transform(men_X_train)\n","women_X_train_scaled = women_preprocessor.fit_transform(women_X_train)\n","\n","men_dtrain = xgb.DMatrix(men_X_train_scaled, label = men_y_train)\n","women_dtrain = xgb.DMatrix(women_X_train_scaled, label = women_y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:52:25.196763Z","iopub.status.busy":"2024-03-21T14:52:25.196345Z","iopub.status.idle":"2024-03-21T14:53:31.286803Z","shell.execute_reply":"2024-03-21T14:53:31.285220Z","shell.execute_reply.started":"2024-03-21T14:52:25.196636Z"},"trusted":true},"outputs":[],"source":["# MEN ONLY Transforming with conferences + p6\n","men_xgb_cv, men_iteration_counts = train_xgboost(men_dtrain)\n","men_oof_preds = oof_predictions(men_X_train_scaled, men_y_train, men_iteration_counts)\n","men_raw_spline_model = raw_spline(men_X_train_scaled, men_y_train, men_oof_preds)\n","men_spline_model = good_spline(men_train_data, men_X_train_scaled, men_y_train, men_oof_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:53:31.289920Z","iopub.status.busy":"2024-03-21T14:53:31.289087Z","iopub.status.idle":"2024-03-21T14:54:04.650049Z","shell.execute_reply":"2024-03-21T14:54:04.648751Z","shell.execute_reply.started":"2024-03-21T14:53:31.289835Z"},"trusted":true},"outputs":[],"source":["# WOMEN ONLY Transforming with conferences + p6\n","women_xgb_cv, women_iteration_counts = train_xgboost(women_dtrain)\n","women_oof_preds = oof_predictions(women_X_train_scaled, women_y_train, women_iteration_counts)\n","women_raw_spline_model = raw_spline(women_X_train_scaled, women_y_train, women_oof_preds)\n","women_spline_model = good_spline(women_train_data, women_X_train_scaled, women_y_train, women_oof_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-03-21T14:54:04.653193Z","iopub.status.busy":"2024-03-21T14:54:04.652286Z","iopub.status.idle":"2024-03-21T14:54:04.668204Z","shell.execute_reply":"2024-03-21T14:54:04.666920Z","shell.execute_reply.started":"2024-03-21T14:54:04.653106Z"},"trusted":true},"outputs":[],"source":["def train_final_model(dtrain, iteration_counts):\n","    xgboost_models = []\n","    for i in range(repeat_cv):\n","        print(f\"Fold repeater {i}\")\n","        xgboost_models.append(\n","            xgb.train(\n","              params = param,\n","              dtrain = dtrain,\n","              num_boost_round = int(iteration_counts[i] * 1.05),\n","              verbose_eval = 50\n","            )\n","        )\n","    return xgboost_models\n","\n","def prediction(xgboost_models, spline_model, dmatrix):\n","    preds = []\n","    for i in range(repeat_cv):\n","        preds.append(np.clip(spline_model[i](np.clip(xgboost_models[i].predict(dmatrix),-30,30)),0.025,0.975))\n","    return sum(preds) / len(preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:54:04.671449Z","iopub.status.busy":"2024-03-21T14:54:04.670530Z","iopub.status.idle":"2024-03-21T14:54:14.003546Z","shell.execute_reply":"2024-03-21T14:54:14.002746Z","shell.execute_reply.started":"2024-03-21T14:54:04.671359Z"},"trusted":true},"outputs":[],"source":["men_xgb_model = train_final_model(men_dtrain, men_iteration_counts)\n","women_xgb_model = train_final_model(women_dtrain, women_iteration_counts)"]},{"cell_type":"markdown","metadata":{"_uuid":"0c06e55e0ed14fd6c3c625e01aca69ae873d74c3"},"source":["# Submission time!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T14:54:14.005761Z","iopub.status.busy":"2024-03-21T14:54:14.005080Z","iopub.status.idle":"2024-03-21T14:54:14.027606Z","shell.execute_reply":"2024-03-21T14:54:14.026792Z","shell.execute_reply.started":"2024-03-21T14:54:14.005678Z"},"trusted":true},"outputs":[],"source":["def analyzeBrackets(bracket_start_num, num_brackets, brackets, season, display = True, mens_only = True):\n","    men_scores = []\n","    women_scores = []\n","    \n","    for num in range(bracket_start_num, num_brackets + bracket_start_num):\n","        reduced_bracket_M = brackets.loc[(brackets.Tournament == 'M') & (brackets.Bracket == num)]\n","        reduced_bracket_W = brackets.loc[(brackets.Tournament == 'W') & (brackets.Bracket == num)]\n","\n","        assert bracket_checker.check_predicted_slots(reduced_bracket_M)\n","        assert bracket_checker.check_consistency(reduced_bracket_M)\n","\n","        assert bracket_checker.check_predicted_slots(reduced_bracket_W)\n","        assert bracket_checker.check_consistency(reduced_bracket_W)\n","        \n","        men_score = evaluate(reduced_bracket_M, season, ['M']) if season != 2024 else 'N/A'\n","        women_score = evaluate(reduced_bracket_W, season, ['W']) if season != 2024 else 'N/A'\n","\n","        men_scores.append(men_score)\n","        women_scores.append(women_score)\n","        \n","        print(\"Bracket #{}:\".format(num))\n","        if display:\n","            print(f\"Men's (Score: {men_score}): \")\n","            prev_letter = None\n","            max_team_name_length = max(len(team_name) for team_name in men_teams['TeamName'])  # Calculate the maximum length of team names\n","            for key, values in bracket_checker.calc_predicted_paths(reduced_bracket_M).items():\n","                current_letter = key[0]\n","                team_id = seeds_2024.loc[seeds_2024['Seed'] == key, 'TeamID'].values[0]\n","                team_name = men_teams.loc[men_teams['TeamID'] == team_id, 'TeamName'].values[0]\n","                \n","                padding = max_team_name_length - len(team_name)\n","                align_width = max_team_name_length + 3  # Additional 3 characters for the space and opening bracket\n","                if prev_letter is not None and current_letter != prev_letter:\n","                    print()\n","                prev_letter = current_letter\n","                print(f\"{key} ({team_name}){' ' * padding}: {' '.join(map(str, values))}\")\n","    \n","            if mens_only == False:\n","                print(f\"\\n\\nWomen's (Score: {women_score}): \")\n","                prev_letter = None\n","                for key, values in bracket_checker.calc_predicted_paths(reduced_bracket_W).items():\n","                    current_letter = key[0]\n","                    team_id = seeds_2024.loc[(seeds_2024['Seed'] == key) & (seeds_2024['Tournament'] == 'W'), 'TeamID'].values[0]\n","                    team_name = women_teams.loc[women_teams['TeamID'] == team_id, 'TeamName'].values[0]\n","\n","                    padding = max_team_name_length - len(team_name)\n","                    align_width = max_team_name_length + 3  # Additional 3 characters for the space and opening bracket\n","                    if prev_letter is not None and current_letter != prev_letter:\n","                        print()\n","                    prev_letter = current_letter\n","                    print(f\"{key} ({team_name}){' ' * padding}: {' '.join(map(str, values))}\")\n","            print(\"\\n\\n\")\n","        else:\n","            print(f\"Men's (Score: {men_score}),  Women's (Score: {women_score}): \")\n","\n","    if season != 2024:\n","        print(f\"\\nMen's (Max Score): {max(men_scores) if season != 2024 else 'N/A'}\")\n","        print(f\"Men's (Average Score): {sum(men_scores) / len(men_scores) if season != 2024 else 'N/A'}\")\n","        print(f\"Women's (Max Score): {max(women_scores) if season != 2024 else 'N/A'}\")\n","        print(f\"Women's (Average Score): {sum(women_scores) / len(women_scores) if season != 2024 else 'N/A'}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:25:15.188788Z","iopub.status.busy":"2024-03-21T15:25:15.188439Z","iopub.status.idle":"2024-03-21T15:25:15.203000Z","shell.execute_reply":"2024-03-21T15:25:15.201863Z","shell.execute_reply.started":"2024-03-21T15:25:15.188702Z"},"trusted":true},"outputs":[],"source":["def findWinner(T1_TeamId, T2_TeamId, xgb_model, spline_model, mens = True, season = 2024, simulate = False):\n","    stats = men_regular_stats if mens else women_regular_stats\n","    stats = stats[stats['Season'] == season]\n","    strongStats = stats[stats['T1_TeamID'] == T1_TeamId].drop(columns = ['Season', 'T1_TeamID']).reset_index(drop=True)\n","    \n","    if mens:\n","        strongAdvStats = T1_adv_stats[(T1_adv_stats['T1_TeamID'] == T1_TeamId) & (T1_adv_stats['Season'] == season)].drop(columns = ['Season', 'T1_TeamID']).reset_index(drop=True)\n","        strongStats = pd.concat([strongStats, strongAdvStats], axis=1)\n","        \n","    weakStats = stats[stats['T1_TeamID'] == T2_TeamId].drop(columns = ['Season', 'T1_TeamID']).reset_index(drop=True)\n","    copyWeakStats = weakStats.copy()\n","    for col in copyWeakStats.columns:\n","        if col.startswith(\"T1_\"):\n","            new_col = col.replace(\"T1_\", \"T2_\")\n","            copyWeakStats.rename(columns={col: new_col}, inplace=True)\n","    if mens:\n","        weakAdvStats = T2_adv_stats[(T2_adv_stats['T2_TeamID'] == T2_TeamId) & (T2_adv_stats['Season'] == season)].drop(columns = ['Season', 'T2_TeamID']).reset_index(drop=True)\n","        copyWeakStats = pd.concat([copyWeakStats, weakAdvStats], axis=1)\n","        \n","    combinedStats = pd.concat([strongStats, copyWeakStats], axis=1)\n","    \n","    combinedStats['Seed_diff'] = combinedStats['T1_seed'] - combinedStats['T2_seed']\n","    if mens:\n","        combinedStats = fix_data(combinedStats)\n","        \n","    combinedStats = men_preprocessor.transform(combinedStats) if mens else women_preprocessor.transform(combinedStats)\n","\n","    dmatrix = xgb.DMatrix(combinedStats)\n","    probability = prediction(xgb_model, spline_model, dmatrix)[0]\n","    if simulate:\n","        winner = np.random.choice([T1_TeamId, T2_TeamId], p=[probability, 1 - probability])\n","        return winner, probability\n","    else:\n","        if (probability > 0.5):\n","            return T1_TeamId, probability\n","        else:\n","            return T2_TeamId, 1-probability"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:25:15.896822Z","iopub.status.busy":"2024-03-21T15:25:15.896192Z","iopub.status.idle":"2024-03-21T15:25:15.917348Z","shell.execute_reply":"2024-03-21T15:25:15.916518Z","shell.execute_reply.started":"2024-03-21T15:25:15.896746Z"},"trusted":true},"outputs":[],"source":["def run_bracket(xgb_model = None, spline_model = None, mens = True, bracket = 1, season = 2024, simulate = False, matchup_cache = {}):\n","    tournament = \"M\" if mens else \"W\"\n","    seeds = seeds_2024.loc[seeds_2024['Tournament']==tournament]\n","    \n","    predictions = pd.read_csv(DATA_PATH + \"sample_submission.csv\")[:0] # Create Blank Dataframe\n","    predictions['Probability'] = -1\n","    predictions = predictions.drop(\"RowId\", axis=1) # We will add back later\n","        \n","    slots = pd.read_csv(DATA_PATH + \"MNCAATourneySlots.csv\")\n","    slots = slots.loc[slots['Season']==2023].reset_index(drop=True) # Slots are the same for any year (except alst 4 play-in games, so take 2023)\n","    slots = slots.iloc[:-4] # 2024_tourney_seeds doesn't include first four    \n","    \n","    teams = seeds_2024.copy().loc[seeds_2024['Tournament']==tournament]\n","    \n","    slot2team = teams[[\"Seed\",\"TeamID\"]].set_index(\"Seed\").to_dict()['TeamID'] # Get Team ID from slot\n","    team2slot = {slot2team[i]:i for i in slot2team.keys()}\n","    round_winners = {i:i for i in list(teams['Seed'])} # Initialize for first round, this will keep track of the seed of who wins each round\n","\n","    for i,v in slots.iterrows():\n","        slot = v['Slot']\n","\n","        strongSeed = round_winners[v['StrongSeed']]\n","        weakSeed = round_winners[v['WeakSeed']]\n","                    \n","        strongId = slot2team[strongSeed]\n","        weakId = slot2team[weakSeed]\n","               \n","        matchup_key = (strongId, weakId)\n","        if matchup_key in matchup_cache:\n","            pick, probability = matchup_cache[matchup_key]\n","            if simulate:\n","                winner = np.random.choice([strongId, weakId], p=[probability, 1 - probability])\n","                pick = team2slot[winner]\n","        else:\n","            if not xgb_model or not spline_model:\n","                pick = strongSeed \n","                probability = 1.0\n","            else:\n","                pick, probability = findWinner(strongId, weakId, xgb_model, spline_model, mens, season, simulate)\n","                pick = team2slot[pick]\n","                matchup_cache[matchup_key] = (pick, probability)\n","\n","        round_winners[slot] = round_winners[pick]\n","#         predictions.loc[len(predictions.index)] = [tournament, bracket, slot, pick, probability]\n","        predictions = predictions.append({'Tournament': tournament, 'Bracket': bracket, 'Slot': slot, 'Team': pick, 'Probability': probability}, ignore_index=True)\n","\n","    return predictions\n","\n","def generate_brackets(num_raw_brackets = 1, num_sim_brackets = 1, men_xgb_model = None, men_spline_model = None, women_xgb_model = None, women_spline_model = None, season = 2024):\n","    matchup_cache = {}\n","    brackets = pd.read_csv(DATA_PATH + \"sample_submission.csv\")[:0].drop(\"RowId\", axis=1)\n","    for bracket in range(1, num_raw_brackets + 1):\n","        mens = run_bracket(men_xgb_model, men_spline_model, True, bracket, season, False, matchup_cache)\n","        womens = run_bracket(women_xgb_model, women_spline_model, False, bracket, season, False, matchup_cache)\n","        brackets = pd.concat([brackets, mens, womens], ignore_index=True, axis=0)\n","        \n","    for bracket in range(num_raw_brackets + 1, num_sim_brackets + num_raw_brackets + 1):\n","        mens = run_bracket(men_xgb_model, men_spline_model, True, bracket, season, True, matchup_cache)\n","        womens = run_bracket(women_xgb_model, women_spline_model, False, bracket, season, True, matchup_cache)\n","        brackets = pd.concat([brackets, mens, womens], ignore_index=True, axis=0)\n","        \n","    brackets['RowId'] = brackets.reset_index().index\n","    brackets = brackets[['RowId', 'Tournament', 'Bracket', 'Slot', 'Team', 'Probability']]\n","    return brackets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:25:17.436888Z","iopub.status.busy":"2024-03-21T15:25:17.436245Z","iopub.status.idle":"2024-03-21T15:25:47.340321Z","shell.execute_reply":"2024-03-21T15:25:47.339311Z","shell.execute_reply.started":"2024-03-21T15:25:17.436815Z"},"trusted":true},"outputs":[],"source":["num_raw_brackets = 5\n","num_sim_brackets = 49994\n","season = 2024\n","\n","brackets = generate_brackets(num_raw_brackets, num_sim_brackets, men_xgb_model, men_spline_model, women_xgb_model, women_spline_model, season)\n","\n","# analyzeBrackets(1, num_raw_brackets + num_sim_brackets, brackets, season, True, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:25:47.342385Z","iopub.status.busy":"2024-03-21T15:25:47.342012Z","iopub.status.idle":"2024-03-21T15:25:47.348574Z","shell.execute_reply":"2024-03-21T15:25:47.347645Z","shell.execute_reply.started":"2024-03-21T15:25:47.342313Z"},"trusted":true},"outputs":[],"source":["def submit(brackets):\n","    brackets = brackets.reset_index(drop=True).drop(columns=['Probability'])\n","    brackets['RowId'] = brackets.reset_index().index\n","    brackets.to_csv(\"/kaggle/working/submission.csv\", index=False)\n","    return brackets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T15:25:47.350957Z","iopub.status.busy":"2024-03-21T15:25:47.350200Z","iopub.status.idle":"2024-03-21T15:25:47.409496Z","shell.execute_reply":"2024-03-21T15:25:47.408369Z","shell.execute_reply.started":"2024-03-21T15:25:47.350510Z"},"trusted":true},"outputs":[],"source":["submit(brackets)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7985011,"sourceId":70068,"sourceType":"competition"},{"datasetId":107552,"sourceId":257301,"sourceType":"datasetVersion"},{"datasetId":2891530,"sourceId":7901549,"sourceType":"datasetVersion"}],"dockerImageVersionId":20477,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
